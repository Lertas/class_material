{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Comparison\n",
    "\n",
    "## Things to note:\n",
    "1. Consistent comparison: ensure all algorithms are evaluated on the *same data*, in the *same way*!\n",
    "2. Use resampling methods, like *cross validation*.\n",
    "3. Use multiple ways for looking at the estimated accuracy (visualise various metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We are going to user the Pima Indians dataset (from Lecture 6):\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "filename = \"../Lecture_6-AppliedMachineLearning/data/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "# df stands for \"Data Frame\"\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "## Create the 10 folds.\n",
    "array = df.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to compare a set of algorithms:\n",
    "1. Logistic Regression\n",
    "2. Linear Discriminant Analysis\n",
    "3. k-Nearest Neighbors\n",
    "4. Decision Trees\n",
    "5. Naive Bayes\n",
    "6. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a list, with one item per algorithm. Each item has a name, and a classifier object.\n",
    "models = []\n",
    "models.append(('LR',  LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('kNN', KNeighborsClassifier()))\n",
    "models.append(('DT',  DecisionTreeClassifier()))\n",
    "models.append(('NB',  GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The scoring function to use\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to evaluate all classifiers, and store results in two lists:\n",
    "results = []\n",
    "names   = []\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=7)\n",
    "  cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  print(\"%03s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.boxplot(results)\n",
    "plt.xticks(list(range(1,len(names)+1)), names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "We are going to use the \"Boston House Price\" dataset:\n",
    "\n",
    "http://lib.stat.cmu.edu/datasets/boston\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "https://www.kaggle.com/vikrishnan/boston-house-prices\n",
    "\n",
    "There are 14 attributes in each case of the dataset. They are:\n",
    "\n",
    " * CRIM - per capita crime rate by town\n",
    " * ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " * INDUS - proportion of non-retail business acres per town.\n",
    " * CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    " * NOX - nitric oxides concentration (parts per 10 million)\n",
    " * RM - average number of rooms per dwelling\n",
    " * AGE - proportion of owner-occupied units built prior to 1940\n",
    " * DIS - weighted distances to five Boston employment centres\n",
    " * RAD - index of accessibility to radial highways\n",
    " * TAX - full-value property-tax rate per \\$10,000\n",
    " * PTRATIO - pupil-teacher ratio by town\n",
    " * B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " * LSTAT - % lower status of the population\n",
    " * MEDV - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(data= np.c_[boston['data'], boston['target']],\n",
    "                     columns= boston['feature_names'].tolist() + ['target'])\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "array = df.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to compare a set of algorithms:\n",
    "1. Linear Regression\n",
    "2. Ridge Regression\n",
    "3. Lasso Regression\n",
    "4. ElasticNet Regression\n",
    "5. k-Nearest Neighbors\n",
    "6. Regression Trees\n",
    "7. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create a list, with one item per algorithm. Each item has a name, and a classifier object.\n",
    "models = []\n",
    "models.append(('LR',      LinearRegression()))\n",
    "models.append(('RIDGE',   Ridge()))\n",
    "models.append(('LASSO',   Lasso()))\n",
    "models.append(('ELASTIC', ElasticNet()))\n",
    "models.append(('kNN',     KNeighborsRegressor()))\n",
    "models.append(('DT',      DecisionTreeRegressor()))\n",
    "models.append(('SVM',     SVR()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The scoring function to use\n",
    "scoring = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to evaluate all classifiers, and store results in two lists:\n",
    "results = []\n",
    "names   = []\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=7)\n",
    "  cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  print(\"%010s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.boxplot(results)\n",
    "plt.xticks(list(range(1,len(names)+1)), names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
